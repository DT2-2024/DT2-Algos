{"cells":[{"cell_type":"markdown","metadata":{"id":"c4eDub3usetv"},"source":["\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44681,"status":"ok","timestamp":1713230351456,"user":{"displayName":"Lacta Learn","userId":"09164211642579531742"},"user_tz":240},"id":"xJOcw688scF_","outputId":"41f358d9-33c9-436d-9f3d-f38842338ec2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"70PVQ6-nsibY","executionInfo":{"status":"ok","timestamp":1713230504201,"user_tz":240,"elapsed":7591,"user":{"displayName":"Lacta Learn","userId":"09164211642579531742"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import os\n","import wave\n","import pylab\n","from pathlib import Path\n","from scipy import signal\n","from scipy.io import wavfile\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","# this should be the folder containing class0 and class1\n","INPUT_DIR = '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/spectro_output/WS_1_mass_intersectections_2_20240415'\n","OUTPUT_DIR = '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/saved_models/WS_1_mass_intersectections_2_20240415_MODEL'"]},{"cell_type":"markdown","metadata":{"id":"fs2GOQyosqcm"},"source":["Data division"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21093,"status":"ok","timestamp":1712506731104,"user":{"displayName":"Lacta Learn","userId":"09164211642579531742"},"user_tz":240},"id":"eIKf7rCGss46","outputId":"bd32bec9-5ec9-4069-a149-724ce4c9852f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 3758 files belonging to 2 classes.\n","Using 3007 files for training.\n","Found 3758 files belonging to 2 classes.\n","Using 751 files for validation.\n"]}],"source":["# Declare constants\n","IMAGE_HEIGHT = 256\n","IMAGE_WIDTH = 256\n","BATCH_SIZE = 16\n","N_CHANNELS = 3\n","N_CLASSES = 2\n","\n","# Make a dataset containing the training spectrograms\n","train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","                                             batch_size=BATCH_SIZE,\n","                                             validation_split=0.2,\n","                                             directory=os.path.join(INPUT_DIR),\n","                                             shuffle=True,\n","                                             color_mode='rgb',\n","                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","                                             subset=\"training\",\n","                                             seed=0)\n","\n","# Make a dataset containing the validation spectrogram\n","valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","                                             batch_size=BATCH_SIZE,\n","                                             validation_split=0.2,\n","                                             directory=os.path.join(INPUT_DIR),\n","                                             shuffle=True,\n","                                             color_mode='rgb',\n","                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","                                             subset=\"validation\",\n","                                             seed=0)"]},{"cell_type":"markdown","metadata":{"id":"CAH2dnPQuCll"},"source":["Modelling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"kRxDkufAsvD5","outputId":"3faf4501-4632-4f5b-c888-0e7a504101a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/14\n","188/188 [==============================] - ETA: 0s - loss: 0.8610 - accuracy: 0.5747"]}],"source":["# Create CNN model\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n","\n","\n","model.add(tf.keras.layers.Conv2D(32, 3, strides=2, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(5, 5)))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","\n","\n","model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","\n","\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(64, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n","\n","\n","# Compile model\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    metrics=['accuracy'],\n",")\n","\n","\n","# Train model for 10 epochs, capture the history\n","history = model.fit(train_dataset, epochs=14, validation_data=valid_dataset)"]},{"cell_type":"markdown","metadata":{"id":"GrjvF75-uGDD"},"source":["Evaluating"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3err_gUuH2N"},"outputs":[],"source":["# Plot the loss curves for training and validation.\n","\n","\n","history_dict = history.history\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","epochs = range(1, len(loss_values)+1)\n","\n","plt.figure(figsize=(8,6))\n","plt.plot(epochs, loss_values, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3x37AGQVuQP2"},"outputs":[],"source":["# Plot the accuracy curves for training and validation.\n","acc_values = history_dict['accuracy']\n","val_acc_values = history_dict['val_accuracy']\n","epochs = range(1, len(acc_values)+1)\n","\n","plt.figure(figsize=(8,6))\n","plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDNFbQ3QuSmV"},"outputs":[],"source":["# Compute the final loss and accuracy\n","final_loss, final_acc = model.evaluate(valid_dataset)\n","print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"]},{"cell_type":"markdown","metadata":{"id":"9s6whnvduTZq"},"source":["Saving the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GG75d-ZRuTGL"},"outputs":[],"source":["model.save(OUTPUT_DIR)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1LQRxhdKJBLXsB-OliHdJPo1UFtjUfsbb","timestamp":1712272197813}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}