{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["DO NOT CHANGE THIS FILE. JUST MAKE COPIES.\n","\n","File name when changing: Date_Parameter Being Changed.ipynb"],"metadata":{"id":"c4eDub3usetv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJOcw688scF_"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import os\n","import wave\n","import pylab\n","from pathlib import Path\n","from scipy import signal\n","from scipy.io import wavfile\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","# this should be the folder containing class0 and class1\n","SPECTO_DIR = '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/spectro_output/ TODO: Parameter being changed_Unique identifier_Audio input folder_Date'\n","OUTPUT_DIR = '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/saved_models/ TODO: Parameter being changed_Unique identifier_Audio input folder_Date'\n","MODEL_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: Date_Parameter Being Changed_Unique Identifier.keras'\n","LOSS_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: loss_Date_Parameter Being Changed_Unique Identifier.png'\n","ACC_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: acc_Date_Parameter Being Changed_Unique Identifier.png'\n","CONF_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: conf_Date_Parameter Being Changed_Unique Identifier.png'\n","NUM_EPOCHS = 14"],"metadata":{"id":"70PVQ6-nsibY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data division"],"metadata":{"id":"fs2GOQyosqcm"}},{"cell_type":"code","source":["# Declare constants\n","IMAGE_HEIGHT = 256\n","IMAGE_WIDTH = 256\n","BATCH_SIZE = 16\n","N_CHANNELS = 3\n","N_CLASSES = 2\n","\n","# Make a dataset containing the training spectrograms\n","train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","                                             batch_size=BATCH_SIZE,\n","                                             validation_split=0.2,\n","                                             directory=os.path.join(SPECTO_DIR),\n","                                             shuffle=True,\n","                                             color_mode='rgb',\n","                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","                                             subset=\"training\",\n","                                             seed=0)\n","\n","# Make a dataset containing the validation spectrogram\n","valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","                                             batch_size=BATCH_SIZE,\n","                                             validation_split=0.2,\n","                                             directory=os.path.join(SPECTO_DIR),\n","                                             shuffle=True,\n","                                             color_mode='rgb',\n","                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","                                             subset=\"validation\",\n","                                             seed=0)"],"metadata":{"id":"eIKf7rCGss46"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Modelling"],"metadata":{"id":"CAH2dnPQuCll"}},{"cell_type":"code","source":["# Create CNN model\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n","\n","\n","model.add(tf.keras.layers.Conv2D(32, 3, strides=2, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(5, 5)))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","\n","model.add(tf.keras.layers.Conv2D(64, 3, strides=2, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(5, 5)))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","\n","model.add(tf.keras.layers.Dense(128, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","\n","model.add(tf.keras.layers.Dense(64, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","\n","\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(64, activation='relu'))\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","\n","model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n","\n","\n","# Compile model\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    metrics=['accuracy'],\n",")\n","\n","\n","# Train model for NUM_EPOCHS epochs, capture the history\n","history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=valid_dataset)"],"metadata":{"id":"kRxDkufAsvD5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluating"],"metadata":{"id":"GrjvF75-uGDD"}},{"cell_type":"code","source":["# Plot the loss curves for training and validation.\n","history_dict = history.history\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","epochs = range(1, len(loss_values)+1)\n","\n","plt.figure(figsize=(8,6))\n","plt.plot(epochs, loss_values, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n","plt.axis([0, NUM_EPOCHS, 0, max(max(loss_values), max(val_loss_values)) + 0.1*max(max(loss_values), max(val_loss_values))])\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.savefig(LOSS_OUTPUT_DIR)\n","plt.show()"],"metadata":{"id":"c3err_gUuH2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the accuracy curves for training and validation.\n","acc_values = history_dict['accuracy']\n","val_acc_values = history_dict['val_accuracy']\n","epochs = range(1, len(acc_values)+1)\n","\n","plt.figure(figsize=(8,6))\n","plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n","plt.axis([0, NUM_EPOCHS, 0, 1])\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.savefig(ACC_OUTPUT_DIR)\n","plt.show()"],"metadata":{"id":"3x37AGQVuQP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute the confusion matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","# Get true labels\n","y_true = []\n","y_pred = []\n","for images, labels in valid_dataset:\n","    y_true.extend(labels.numpy())\n","    y_pred.extend( np.argmax( model.predict(images) , axis = - 1) )\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n","plt.colorbar()\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.xticks(np.arange(N_CLASSES))\n","plt.yticks(np.arange(N_CLASSES))\n","for i in range(N_CLASSES):\n","    for j in range(N_CLASSES):\n","        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n","plt.savefig(CONF_OUTPUT_DIR)\n","plt.show()"],"metadata":{"id":"x20v49-kzhD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute the final loss and accuracy\n","final_loss, final_acc = model.evaluate(valid_dataset)\n","print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"],"metadata":{"id":"SDNFbQ3QuSmV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saving the model"],"metadata":{"id":"9s6whnvduTZq"}},{"cell_type":"code","source":["model.save(MODEL_OUTPUT_DIR)"],"metadata":{"id":"GG75d-ZRuTGL"},"execution_count":null,"outputs":[]}]}