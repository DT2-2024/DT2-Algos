{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4eDub3usetv"
   },
   "source": [
    "DO NOT CHANGE THIS FILE. JUST MAKE COPIES.\n",
    "\n",
    "File name when changing: Date_Parameter Being Changed.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "70PVQ6-nsibY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wave\n",
    "import pylab\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# this should be the folder containing class0 and class1\n",
    "SPECTO_DIR = '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/spectro_output/ TODO: Parameter being changed_Unique identifier_Audio input folder_Date'\n",
    "OUTPUT_DIR = '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/saved_models/ TODO: Parameter being changed_Unique identifier_Audio input folder_Date'\n",
    "MODEL_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: Date_Parameter Being Changed_Unique Identifier.keras'\n",
    "LOSS_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: loss_Date_Parameter Being Changed_Unique Identifier.png'\n",
    "ACC_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: acc_Date_Parameter Being Changed_Unique Identifier.png'\n",
    "CONF_OUTPUT_DIR = OUTPUT_DIR + '/' + 'TODO: conf_Date_Parameter Being Changed_Unique Identifier.png'\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fs2GOQyosqcm"
   },
   "source": [
    "Data division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eIKf7rCGss46"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/spectro_output/ TODO: Parameter being changed_Unique identifier_Audio input folder_Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24196\\2823157191.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Make a dataset containing the training spectrograms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[0;32m     10\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                              \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lactalearn\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links)\u001b[0m\n\u001b[0;32m    173\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m   image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[0;32m    176\u001b[0m       \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lactalearn\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \"\"\"\n\u001b[0;32m     64\u001b[0m   \u001b[0minferred_class_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[0minferred_class_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/My Drive/DT2_2023/Spring 2024/Audio_models/spectro_output/ TODO: Parameter being changed_Unique identifier_Audio input folder_Date'"
     ]
    }
   ],
   "source": [
    "# Declare constants\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "BATCH_SIZE = 16\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 2\n",
    "\n",
    "# Make a dataset containing the training spectrograms\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             directory=os.path.join(SPECTO_DIR),\n",
    "                                             shuffle=True,\n",
    "                                             color_mode='rgb',\n",
    "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                             subset=\"training\",\n",
    "                                             seed=0)\n",
    "\n",
    "# Make a dataset containing the validation spectrogram\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             directory=os.path.join(SPECTO_DIR),\n",
    "                                             shuffle=True,\n",
    "                                             color_mode='rgb',\n",
    "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                             subset=\"validation\",\n",
    "                                             seed=0)\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(valid_dataset)\n",
    "test_dataset = valid_dataset.take((2*val_batches) // 3)\n",
    "valid_dataset = valid_dataset.skip((2*val_batches) // 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAH2dnPQuCll"
   },
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRxDkufAsvD5"
   },
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(5, 5)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(5, 5)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "# Train model for NUM_EPOCHS epochs, capture the history\n",
    "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrjvF75-uGDD"
   },
   "source": [
    "Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3err_gUuH2N"
   },
   "outputs": [],
   "source": [
    "# Plot the loss curves for training and validation.\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.axis([0, NUM_EPOCHS, 0, max(max(loss_values), max(val_loss_values)) + 0.1*max(max(loss_values), max(val_loss_values))])\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(LOSS_OUTPUT_DIR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3x37AGQVuQP2"
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy curves for training and validation.\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "epochs = range(1, len(acc_values)+1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
    "plt.axis([0, NUM_EPOCHS, 0, 1])\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(ACC_OUTPUT_DIR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x20v49-kzhD9"
   },
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for images, labels in valid_dataset:\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend( np.argmax( model.predict(images) , axis = - 1) )\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.xticks(np.arange(N_CLASSES))\n",
    "plt.yticks(np.arange(N_CLASSES))\n",
    "for i in range(N_CLASSES):\n",
    "    for j in range(N_CLASSES):\n",
    "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
    "plt.savefig(CONF_OUTPUT_DIR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDNFbQ3QuSmV"
   },
   "outputs": [],
   "source": [
    "# Compute the final loss and accuracy\n",
    "final_loss, final_acc = model.evaluate(valid_dataset)\n",
    "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s6whnvduTZq"
   },
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GG75d-ZRuTGL"
   },
   "outputs": [],
   "source": [
    "model.save(MODEL_OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
